# llama2-on-cpu


### Step 1 
git clone

### Step 2

Create virtual environment:

```bash
conda create -n cpullama python=3.10 -y`
```

### Step 3
```bash
conda activate cpullama
```

### Step 4
```bash
pip install -r requirements.txt
```

# Download quantize model from the link provided and keep the model in the model directory:

## llama2 model


link:
https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main

