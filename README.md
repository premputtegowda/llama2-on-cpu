# llama2-on-cpu


### Step 1 
git clone

### Step 2

Create virtual environment:

```bash
conda create -n llama_cpu python=3.10 -y`
```

### Step 3
```bash
conda activate llama_cpu
```

### Step 4
```bash
pip install -r requirements.txt
```

# Download quantize model from the link provided and keep the model in the model directory:


## Download the Llama 2 Model:

llama-2-7b-chat.ggmlv3.q4_0.bin
from link:
https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main

